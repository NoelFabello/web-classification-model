{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desambiguación de significados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "La intención del proyecto es identificar diferentes significados en los textos para observar si así se puede extraer más información de los textos. Para esto, lo que se va a realizar es una modificación del texto asignando un identificador a las palabras que se han desambiguado con la notación `palabra_n_codigo`. \n",
    "\n",
    "Debido a que no existe una librería que realice la desambiguación tal y como se requiere en este proyecto, se ha decidido crear un algoritmo de desambiguación apoyándose en la librería `WordNet` de nltk. Esta librería contiene un diccionario de palabras, para cada palabra almacena su acepción y sus hiperónimos, de forma que se crea un árbol con las palabras en inglés.\n",
    "\n",
    "### Solución\n",
    "Dado que los árboles de palabras en `WordNet` están divididos por tipos de palabras, en este proyecto para acotar el problema se ha decidido desambiguar los sustantivos. El algoritmo desarrollado se apoya en la métrica JCN. La librería permite obtener acepciones posibles para un término en inglés. Se ha utilizado esta característica para comparar todas las acepciones de los sustantivos 2 a 2 y así obtener las definiciones de palabras que estén más relacionadas, asumiendo que es más probable que sean las correctas. Una vez obtenida la desambiguación, se sustituyen los sustantivos por los identificadores que ofrece `WordNet` para cada sustantivo.\n",
    "\n",
    "#### Exploración de otras posibilidades\n",
    "Antes de llegar a esta solución se han creado algoritmos basados en otras métricas. Un ejemplo se encuentra en el archivo `Disambiguation_cosine_distance` donde se ha intentado crear un algoritmo que calcula la similitud entre definiciones de sustantivos basado en la distancia coseno.\n",
    "Otro intento se ha basado en simplemente dar por hecho que las definiciones con el hiperónimo más cercano tienen más relación, pero ha dado peores resultados que la métrica JNC.\n",
    "\n",
    "#### Medida de similitud JNC\n",
    "La similitud de JCN (Jiang-Conrath) es una medida de similitud semántica entre dos palabras en un espacio vectorial. Esta métrica se basa en la idea de que palabras que comparten información más específica tienen una similitud semántica más alta. La fórmula para calcular la similitud de JCN entre dos palabras \\(w_1\\) y \\(w_2\\) es la siguiente:\n",
    "\n",
    "$$\n",
    "JCN(w_1, w_2) = \\frac{1}{JCN\\_distance(w_1, w_2) + 1}\n",
    "$$\n",
    "\n",
    "Donde \\(JCN\\_distance(w_1, w_2)\\) es la distancia de Jiang-Conrath entre las dos palabras, y se calcula de la siguiente manera:\n",
    "\n",
    "$$\n",
    "JCN\\_distance(w_1, w_2) = IC(w_1) + IC(w_2) - 2 \\times IC(LCA(w_1, w_2))\n",
    "$$\n",
    "Aquí, los términos utilizados son:\n",
    "\n",
    "- \\(IC(w)\\): La información de contenido de la palabra \\(w\\). Esta medida se basa en la frecuencia de aparición de la palabra en un corpus y se utiliza para cuantificar la cantidad de información que proporciona la palabra. Cuanto menos frecuente sea una palabra, más información proporciona y, por lo tanto, su \\(IC\\) es mayor.\n",
    "\n",
    "- \\(LCA(w_1, w_2)\\): El ancestro común más bajo de las palabras \\(w_1\\) y \\(w_2\\) en una jerarquía de conceptos, en este caso la de WordNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de la similitud\n",
    "A continuación el algoritmo que calcula las acepciones que más se parezcan para 2 sustantivos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la información de contenido de WordNet\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "def calculate_jcn_similarity(word1, word2):\n",
    "    # Obtener los synsets para cada palabra\n",
    "    synsets_word1 = wn.synsets(word1, pos=wn.NOUN)\n",
    "    synsets_word2 = wn.synsets(word2, pos=wn.NOUN)\n",
    "\n",
    "    max_similarity = -1\n",
    "    best_synset_word1 = None\n",
    "    best_synset_word2 = None\n",
    "\n",
    "    # Calcular la similitud JCN entre los synsets de las dos palabras\n",
    "    for synset1 in synsets_word1:\n",
    "        for synset2 in synsets_word2:\n",
    "            similarity = synset1.jcn_similarity(synset2, brown_ic)\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_synset_word1 = synset1\n",
    "                best_synset_word2 = synset2\n",
    "                \n",
    "    if best_synset_word1 is None : best_synset_word1 = word1\n",
    "    if best_synset_word2 is None : best_synset_word2 = word2\n",
    "    \n",
    "    return best_synset_word1, best_synset_word2, max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desambiguación de textos\n",
    "Para realizar la desambiguación primero se tokeniza el texto y se clasifican las palabras según su clase, esto se utilizará para obtener los sustantivos y guardar las posiciones del texto en las que luego irán los identificadores.  \n",
    "\n",
    "Una vez obtenidos los sustantivos, se procede a recorrer la lista que los contiene, comparando siempre una palabra con la siguiente en el texto. Para estas palabras se obtiene las acepciones que más relación tengan. El algoritmo tiene flexibilidad para corregir una acepción cuando encuentra otra que tiene más relación. Es decir, para 3 palabras `A`, `B` y `C`, el algoritmo:  \n",
    "-  Compara `A` y `B`, obteniendo los significados que tengan más relación.\n",
    "-  Compara `B` y `C` para obtener el significado de la palabra `C`, pero si existe una acepción de `B` que se parezca más a `C` que a `A`, se actualiza.\n",
    "\n",
    "Cuando se termina la desambiguación, se identifican los sustantivos que se han desambiguado y se cambian en el texto por el identificador de `WordNet`, con el formato `palabra_n_codigo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguateText(text, verbose_ = False):\n",
    "    # Tokenizado\n",
    "    tokens = word_tokenize(text)\n",
    "    # Etiquetado y obtención de substantivos\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    if verbose_: print(pos_tags)\n",
    "    nouns = [word for word, tag in pos_tags if ((tag == 'NN' or tag == ' NNS') and len(wn.synsets('word', pos=wn.NOUN)) > 0)]\n",
    "    if verbose_: print('Nouns to Disambiguate: ', nouns)\n",
    "    #Inicializamos variables de apoyo\n",
    "    last_noun = None\n",
    "    last_sim = -1\n",
    "    toret_nouns = []\n",
    "    #Desambiguación del texto\n",
    "    for i in range(len(nouns)):\n",
    "        if i < len(nouns)-1:\n",
    "            if verbose_: print('Disambiguate: ',nouns[i],' vs ',nouns[i+1])\n",
    "            first_noun, second_noun, similarity = calculate_jcn_similarity(nouns[i], nouns[i+1])\n",
    "            if verbose_: print(first_noun, ' ', second_noun, ' ', similarity, ' ', last_sim)\n",
    "            if similarity >= last_sim:\n",
    "                toret_nouns.append(first_noun)\n",
    "            else:\n",
    "                toret_nouns.append(last_noun)\n",
    "            last_sim = similarity\n",
    "            last_noun = second_noun\n",
    "        else:\n",
    "            second_noun, first_noun, similarity = calculate_jcn_similarity(nouns[i], nouns[i-1])\n",
    "            toret_nouns.append(second_noun)\n",
    "            if verbose_: print(second_noun, ' ', first_noun)\n",
    "    if verbose_:\n",
    "        print(toret_nouns)\n",
    "        for i in toret_nouns:\n",
    "            if type(i) is str:\n",
    "                print(i)\n",
    "            else:\n",
    "                print(i.name(),'\\n',i.definition())\n",
    "    # Substitución de las palabras desambiguadas en el texto\n",
    "\n",
    "    for i in range(len(nouns)):\n",
    "        index = tokens.index(nouns[i])\n",
    "        if type(toret_nouns[i]) is str:\n",
    "            tokens[index] = toret_nouns[i]\n",
    "        else:\n",
    "            tokens[index] = toret_nouns[i].name()\n",
    "    if verbose_: print(tokens)        \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP'), ('withdrew', 'VBD'), ('cash', 'NN'), ('from', 'IN'), ('the', 'DT'), ('bank', 'NN'), ('and', 'CC'), ('fished', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('river', 'NN'), ('.', '.')]\n",
      "Nouns to Disambiguate:  ['cash', 'bank', 'river']\n",
      "Disambiguate:  cash  vs  bank\n",
      "Synset('cash.n.02')   Synset('bank.n.05')   0.08397598296431394   -1\n",
      "Disambiguate:  bank  vs  river\n",
      "Synset('bank.n.07')   Synset('river.n.01')   0.07049299927013367   0.08397598296431394\n",
      "Synset('river.n.01')   Synset('bank.n.07')\n",
      "[Synset('cash.n.02'), Synset('bank.n.05'), Synset('river.n.01')]\n",
      "cash.n.02 \n",
      " prompt payment for goods or services in currency or by check\n",
      "bank.n.05 \n",
      " a supply or stock held in reserve for future use (especially in emergencies)\n",
      "river.n.01 \n",
      " a large natural stream of water (larger than a creek)\n",
      "['John', 'withdrew', 'cash.n.02', 'from', 'the', 'bank.n.05', 'and', 'fished', 'by', 'the', 'river.n.01', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'John withdrew cash.n.02 from the bank.n.05 and fished by the river.n.01 .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"John withdrew cash from the bank and fished by the river.\"\n",
    "disambiguateText(example, verbose_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratado del texto\n",
    "Para realizar la desambiguación, primero se eliminan las stopwords y caracteres que no sean letras o espacios, luego se realiza la desambiguación y se almacena.\n",
    "\n",
    "El identificador original que aporta `WordNet` para los sustantivos tiene la forma `palabra.n.codigo`, pero los puntos dan problemas a la hora de aplicar un vectorizer y se separa el identificador en `palabra`, `n` y `codigo`, perdiendo así la desambiguación, por lo que se ha decidido cambiar `.` por `_` para evitar el problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       marc_n_01 east_n_01 fiuczynski south_n_03 home...\n",
       "1       document_n_01 information_n_01 server_n_03 des...\n",
       "2       last modified wednesday 20 nov 96 07 36 47 gre...\n",
       "3       c_n_10 537 programming assignment_n_02 three_n...\n",
       "4       kurt partridge_n_01 kurt partridge academic in...\n",
       "                              ...                        \n",
       "1654    c_n_10 110 section_n_01 2 late policy_n_01 lat...\n",
       "1655    last modified saturday 03 declination_n_03 94 ...\n",
       "1656    last modified saturday 12 oct 96 07 33 01 gree...\n",
       "1657    last modified tuesday 19 nov 96 19 34 50 gmt c...\n",
       "1658    nancy hall computer_n_01 sciences department_n...\n",
       "Name: text, Length: 1659, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df = pd.read_json('dataTest.json')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "disambiguatedText = df['text'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stop_words]))\n",
    "disambiguatedText = disambiguatedText.apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "disambiguatedText = disambiguatedText.apply(disambiguateText)\n",
    "disambiguatedText = disambiguatedText.apply(lambda x: re.sub(r'\\.n\\.', '_n_', x))\n",
    "disambiguatedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = disambiguatedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('disambiguated_dataTest.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
