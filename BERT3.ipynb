{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87196de-1b5b-48fc-beef-7b78a5449a8b",
      "metadata": {
        "id": "b87196de-1b5b-48fc-beef-7b78a5449a8b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93dd178-faed-4e61-84f4-fca1376612c0",
      "metadata": {
        "id": "b93dd178-faed-4e61-84f4-fca1376612c0",
        "outputId": "b5cfd75d-f5a9-4047-ad16-63b1531bf0cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\olaya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2b2056-abb1-475b-af24-89a95add3bbb",
      "metadata": {
        "id": "3f2b2056-abb1-475b-af24-89a95add3bbb",
        "outputId": "d740d3c2-3e26-4849-c51b-bb8b040af06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame con la mitad de las filas seleccionadas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aaexyuw</td>\n",
              "      <td>\\n571 Main Page\\n\\n\\nComputer Science 571\\nCON...</td>\n",
              "      <td>course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>achmly</td>\n",
              "      <td>\\n\\n\\nECE/CS 752 Spring 1996\\n\\n\\n\\n\\nECE/CS 7...</td>\n",
              "      <td>course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ackfxrep</td>\n",
              "      <td>\\n\\nEECS401 Web Page for Fall '96\\n\\n\\nWelcome...</td>\n",
              "      <td>course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>advmiv</td>\n",
              "      <td>\\n\\nCS 545 - Introduction to Robotics\\n\\n\\n\\n ...</td>\n",
              "      <td>course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>agdvsjkw</td>\n",
              "      <td>\\n\\n\\nCS325 Page\\n\\n\\n\\n\\n\\n\\n\\nCS325 Artifici...</td>\n",
              "      <td>course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6614</th>\n",
              "      <td>zwmfqj</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n Home page of Ka Yee Yeung\\n\\n\\n\\n...</td>\n",
              "      <td>student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6616</th>\n",
              "      <td>zwpln</td>\n",
              "      <td>\\nKris Kocan's Home Page\\n\\nMy Home Page\\n\\nPr...</td>\n",
              "      <td>student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6618</th>\n",
              "      <td>zxgxje</td>\n",
              "      <td>\\n\\nHomePage of Daqing Li\\n\\n\\n\\n\\nWelcome to ...</td>\n",
              "      <td>student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6620</th>\n",
              "      <td>zyrphu</td>\n",
              "      <td>\\n\\n\\n\\nHOME \\n\\n\\n\\n\\n \\n  \\n \\n\\n\\nMarla Bak...</td>\n",
              "      <td>student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6622</th>\n",
              "      <td>zywpsym</td>\n",
              "      <td>\\nEric's Home Page\\nEric's SUPER DUPER Home Pa...</td>\n",
              "      <td>student</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3312 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                               text    label\n",
              "0      aaexyuw  \\n571 Main Page\\n\\n\\nComputer Science 571\\nCON...   course\n",
              "2       achmly  \\n\\n\\nECE/CS 752 Spring 1996\\n\\n\\n\\n\\nECE/CS 7...   course\n",
              "4     ackfxrep  \\n\\nEECS401 Web Page for Fall '96\\n\\n\\nWelcome...   course\n",
              "6       advmiv  \\n\\nCS 545 - Introduction to Robotics\\n\\n\\n\\n ...   course\n",
              "8     agdvsjkw  \\n\\n\\nCS325 Page\\n\\n\\n\\n\\n\\n\\n\\nCS325 Artifici...   course\n",
              "...        ...                                                ...      ...\n",
              "6614    zwmfqj  \\n\\n\\n\\n\\n\\n Home page of Ka Yee Yeung\\n\\n\\n\\n...  student\n",
              "6616     zwpln  \\nKris Kocan's Home Page\\n\\nMy Home Page\\n\\nPr...  student\n",
              "6618    zxgxje  \\n\\nHomePage of Daqing Li\\n\\n\\n\\n\\nWelcome to ...  student\n",
              "6620    zyrphu  \\n\\n\\n\\nHOME \\n\\n\\n\\n\\n \\n  \\n \\n\\n\\nMarla Bak...  student\n",
              "6622   zywpsym  \\nEric's Home Page\\nEric's SUPER DUPER Home Pa...  student\n",
              "\n",
              "[3312 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_data = pd.read_json('datosParsed3.json')\n",
        "#display(train_data)\n",
        "# Selecciona una fila, omite la siguiente, y así sucesivamente\n",
        "train_data = train_data.iloc[::2]\n",
        "print(\"\\nDataFrame con la mitad de las filas seleccionadas:\")\n",
        "display(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "650986b5-bf60-4a16-9225-eb2f049bbd48",
      "metadata": {
        "id": "650986b5-bf60-4a16-9225-eb2f049bbd48",
        "outputId": "0e42dcfd-4ad4-44f9-f977-b540c063fa8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "torch.Size([2649, 512])\n",
            "torch.Size([2649, 512])\n"
          ]
        }
      ],
      "source": [
        "# Inicializar el tokenizador BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
        "\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "train_data['text'] = train_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Extraer textos y etiquetas\n",
        "train_texts = train_data['text'].tolist()\n",
        "train_labels = train_data['label'].tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizar y convertir a tensores\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, return_tensors='pt')\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "# Mostrar información sobre las codificaciones\n",
        "print(train_encodings.keys())\n",
        "print(train_encodings['input_ids'].shape)\n",
        "print(train_encodings['attention_mask'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c04426d5-50c6-4646-bbf5-050c43019469",
      "metadata": {
        "id": "c04426d5-50c6-4646-bbf5-050c43019469"
      },
      "outputs": [],
      "source": [
        "# Crear un conjunto de datos personalizado\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "        self.label_mapping = {'course': 0, 'department': 1, 'faculty': 2, 'other': 3, 'project': 4, 'staff': 5, 'student': 6}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "        # Convierte la etiqueta a tipo numérico usando el mapeo\n",
        "        item['labels'] = torch.tensor(self.label_mapping[self.labels[idx]])\n",
        "\n",
        "        return item\n",
        "\n",
        "# Crear conjuntos de datos y DataLoader\n",
        "train_dataset = CustomDataset(train_encodings, y_train)\n",
        "test_dataset = CustomDataset(test_encodings, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7745cb-9b86-4762-a75d-eaec4c45a073",
      "metadata": {
        "id": "4c7745cb-9b86-4762-a75d-eaec4c45a073",
        "outputId": "ba296b3a-2793-457b-eadf-3747ec4704ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "C:\\Users\\olaya\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Inicializar el modelo BERT para clasificación de sentimientos\n",
        "model = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment',\n",
        "                                                      num_labels=len(train_data['label'].unique()),\n",
        "                                                      ignore_mismatched_sizes=True)\n",
        "\n",
        "# Configurar el dispositivo a GPU si está disponible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Inicializar el optimizador\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ec4bd5-9e8b-4583-871b-ad0bbd6c5281",
      "metadata": {
        "id": "42ec4bd5-9e8b-4583-871b-ad0bbd6c5281",
        "outputId": "db946bca-9080-4ae7-be77-712e033bc2ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\olaya\\AppData\\Local\\Temp\\ipykernel_23396\\1258142799.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ],
      "source": [
        "# Establecer el modelo en modo de entrenamiento\n",
        "model.train()\n",
        "\n",
        "# Definir la función de pérdida (criterio)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Número de épocas (ajusta según sea necesario)\n",
        "num_epochs = 3\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        # Transferir datos al dispositivo (GPU si está disponible)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Realizar la propagación hacia adelante\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Realizar la retropropagación y la actualización de parámetros\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95a83f30-2ba8-4c2b-a9ff-cff1b8dd8b28",
      "metadata": {
        "id": "95a83f30-2ba8-4c2b-a9ff-cff1b8dd8b28"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar train_dataset\n",
        "with open('bert3_train_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(train_dataset, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97aaff96-72ab-456b-a435-2bc7b2cbaed7",
      "metadata": {
        "id": "97aaff96-72ab-456b-a435-2bc7b2cbaed7"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'bert3_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75c62e2-fe65-4c40-aaca-857a42f78d5a",
      "metadata": {
        "id": "a75c62e2-fe65-4c40-aaca-857a42f78d5a",
        "outputId": "ef0296c2-2ff9-4bf2-a7f7-25d0e4098f1c"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "BertForSequenceClassification.__init__() missing 1 required positional argument: 'config'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model directly from the saved file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m restored_model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m restored_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert3_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Move the model to the appropriate device\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: BertForSequenceClassification.__init__() missing 1 required positional argument: 'config'"
          ]
        }
      ],
      "source": [
        "# IGNORAR CELDA\n",
        "# Load the model directly from the saved file\n",
        "restored_model = BertForSequenceClassification()\n",
        "restored_model.load_state_dict(torch.load('bert3_model.pth'))\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "restored_model.to(device)\n",
        "\n",
        "# Initialize the optimizer (make sure to use the same parameters as before)\n",
        "optimizer = AdamW(restored_model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Load the optimizer state dictionary\n",
        "optimizer.load_state_dict(torch.load('bert3_optimizer.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202646ea-b363-46fc-b55c-fb8862c57619",
      "metadata": {
        "id": "202646ea-b363-46fc-b55c-fb8862c57619",
        "outputId": "60a4fe37-1619-4dc4-de6d-30264955bef5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\olaya\\AppData\\Local\\Temp\\ipykernel_23396\\1258142799.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94       278\n",
            "           1       0.84      1.00      0.91        57\n",
            "           2       0.90      0.97      0.93       354\n",
            "           3       0.97      0.88      0.92      1225\n",
            "           4       0.58      0.96      0.72       161\n",
            "           5       0.71      0.79      0.75        43\n",
            "           6       0.96      0.92      0.94       531\n",
            "\n",
            "    accuracy                           0.91      2649\n",
            "   macro avg       0.84      0.92      0.87      2649\n",
            "weighted avg       0.93      0.91      0.91      2649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambiar el modelo a modo de evaluación\n",
        "model.eval()\n",
        "\n",
        "# Listas para almacenar las predicciones y etiquetas reales\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        # Transferir datos al dispositivo (GPU si está disponible)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Realizar la propagación hacia adelante sin realizar la retropropagación\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Obtener las predicciones y las etiquetas reales\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        # Almacenar las predicciones y las etiquetas reales\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "# Calcular y mostrar el informe de clasificación\n",
        "print(classification_report(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dea1db8-5dad-43b0-8db7-b1858c6927f5",
      "metadata": {
        "id": "3dea1db8-5dad-43b0-8db7-b1858c6927f5"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_json('dataTestParsed3.json')\n",
        "\n",
        "# Preprocesar el conjunto de datos de prueba de la misma manera que el conjunto de entrenamiento\n",
        "test_data['text'] = test_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))\n",
        "\n",
        "# Extraer textos y etiquetas (si están disponibles en el conjunto de prueba)\n",
        "test_texts = test_data['text']\n",
        "\n",
        "# Tokenizar y convertir a tensores\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, return_tensors='pt').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fcfa4fa-7430-40bd-a5e8-d454df723c75",
      "metadata": {
        "id": "7fcfa4fa-7430-40bd-a5e8-d454df723c75"
      },
      "outputs": [],
      "source": [
        "# Cambiar el modelo a modo de evaluación\n",
        "model.eval()\n",
        "\n",
        "# Listas para almacenar las predicciones en el conjunto de prueba sin etiquetas\n",
        "test_preds_without_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(len(test_encodings['input_ids'])):\n",
        "        # Transferir datos al dispositivo (GPU si está disponible)\n",
        "        input_ids = test_encodings['input_ids'][i].unsqueeze(0).to(device)\n",
        "        attention_mask = test_encodings['attention_mask'][i].unsqueeze(0).to(device)\n",
        "\n",
        "        # Realizar la propagación hacia adelante sin realizar la retropropagación\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Obtener las predicciones\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Almacenar las predicciones\n",
        "        test_preds_without_labels.extend(preds)\n",
        "\n",
        "# Obtener los nombres de los archivos (id) del conjunto de prueba\n",
        "test_ids = test_data['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12dca563-3eec-4be2-9f62-0f3529d8df1c",
      "metadata": {
        "id": "12dca563-3eec-4be2-9f62-0f3529d8df1c",
        "outputId": "51cc909c-0229-4287-dc52-6e8121e58388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           id    label\n",
            "0     aaclkul  student\n",
            "1     aagelci  project\n",
            "2     aangjmn    other\n",
            "3      aawnpc    other\n",
            "4     abdjgiz  student\n",
            "...       ...      ...\n",
            "1654    zxmmn    other\n",
            "1655   zxwkru    other\n",
            "1656  zybimtt    other\n",
            "1657  zypnixf  project\n",
            "1658   zzszho  student\n",
            "\n",
            "[1659 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Mapear las predicciones a las etiquetas reales usando el diccionario inverso de la asignación de etiquetas\n",
        "label_mapping = {train_dataset.label_mapping[label]: label for label in train_dataset.label_mapping}\n",
        "\n",
        "# Crear un DataFrame con las predicciones\n",
        "predictions_df = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'label': [label_mapping[pred] for pred in test_preds_without_labels]\n",
        "})\n",
        "\n",
        "# Mostrar el DataFrame con las predicciones\n",
        "print(predictions_df)\n",
        "\n",
        "nombre_archivo = 'ENXEBRE-Bert-Sentimental-mitad-datatrain-bs-2.csv'\n",
        "predictions_df.to_csv(nombre_archivo, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd677a92-0db2-47b1-b133-bc4728d1da4f",
      "metadata": {
        "id": "fd677a92-0db2-47b1-b133-bc4728d1da4f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}