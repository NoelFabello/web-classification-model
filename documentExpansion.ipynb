{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansión de documentos\n",
    "En este proyecto se ha utilizado el modelo DocTTTTTquery. Este modelo permite generar texto a partir de otro dado de diferentes formas. Las opciones que se han probado en el proyecto son: generación de resúmenes, generación de respuesta y generación de preguntas. Observando los resultados se ha concluido que la forma de expansión que más información aporta es la de generación de preguntas, ya que es la que más vocabulario nuevo incluye. De esta forma, para extender los documentos se han realizado preguntas que el texto pueda responder, y se han añadido al final de los textos. Esto aporta contenido nuevo, sin perder información ni perder el tema importante del documento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expansión de documentos se ha realizado sobre le conjunto de entrenamiento, sin modificar ni expandir el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"dataTrain.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "100\n",
      "0.005032965926820675\n",
      "200\n",
      "0.01006593185364135\n",
      "300\n",
      "0.015098897780462027\n",
      "400\n",
      "0.0201318637072827\n",
      "500\n",
      "0.025164829634103377\n",
      "600\n",
      "0.030197795560924053\n",
      "700\n",
      "0.035230761487744726\n",
      "800\n",
      "0.0402637274145654\n",
      "900\n",
      "0.04529669334138608\n",
      "1000\n",
      "0.050329659268206754\n",
      "1100\n",
      "0.05536262519502743\n",
      "1200\n",
      "0.060395591121848106\n",
      "1300\n",
      "0.06542855704866878\n",
      "1400\n",
      "0.07046152297548945\n",
      "1500\n",
      "0.07549448890231013\n",
      "1600\n",
      "0.0805274548291308\n",
      "1700\n",
      "0.08556042075595148\n",
      "1800\n",
      "0.09059338668277216\n",
      "1900\n",
      "0.09562635260959283\n",
      "2000\n",
      "0.10065931853641351\n",
      "2100\n",
      "0.10569228446323418\n",
      "2200\n",
      "0.11072525039005486\n",
      "2300\n",
      "0.11575821631687554\n",
      "2400\n",
      "0.12079118224369621\n",
      "2500\n",
      "0.12582414817051688\n",
      "2600\n",
      "0.13085711409733755\n",
      "2700\n",
      "0.13589008002415823\n",
      "2800\n",
      "0.1409230459509789\n",
      "2900\n",
      "0.14595601187779958\n",
      "3000\n",
      "0.15098897780462026\n",
      "3100\n",
      "0.15602194373144093\n",
      "3200\n",
      "0.1610549096582616\n",
      "3300\n",
      "0.16608787558508228\n",
      "3400\n",
      "0.17112084151190296\n",
      "3500\n",
      "0.17615380743872364\n",
      "3600\n",
      "0.1811867733655443\n",
      "3700\n",
      "0.186219739292365\n",
      "3800\n",
      "0.19125270521918566\n",
      "3900\n",
      "0.19628567114600634\n",
      "4000\n",
      "0.20131863707282702\n",
      "4100\n",
      "0.2063516029996477\n",
      "4200\n",
      "0.21138456892646837\n",
      "4300\n",
      "0.21641753485328905\n",
      "4400\n",
      "0.22145050078010972\n",
      "4500\n",
      "0.2264834667069304\n",
      "4600\n",
      "0.23151643263375107\n",
      "4700\n",
      "0.23654939856057175\n",
      "4800\n",
      "0.24158236448739243\n",
      "4900\n",
      "0.2466153304142131\n",
      "5000\n",
      "0.25164829634103375\n",
      "5100\n",
      "0.2566812622678544\n",
      "5200\n",
      "0.2617142281946751\n",
      "5300\n",
      "0.2667471941214958\n",
      "5400\n",
      "0.27178016004831645\n",
      "5500\n",
      "0.27681312597513713\n",
      "5600\n",
      "0.2818460919019578\n",
      "5700\n",
      "0.2868790578287785\n",
      "5800\n",
      "0.29191202375559916\n",
      "5900\n",
      "0.29694498968241984\n",
      "6000\n",
      "0.3019779556092405\n",
      "6100\n",
      "0.3070109215360612\n",
      "6200\n",
      "0.31204388746288186\n",
      "6300\n",
      "0.31707685338970254\n",
      "6400\n",
      "0.3221098193165232\n",
      "6500\n",
      "0.3271427852433439\n",
      "6600\n",
      "0.33217575117016457\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "model_name = 'doc2query/all-with_prefix-t5-base-v1'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "prefix = \"answer2question\"\n",
    "outputColumn = []\n",
    "cont = 0\n",
    "for i in df['text']:\n",
    "    text = prefix+\": \"+ i\n",
    "    input_ids = tokenizer.encode(text, max_length=384, truncation=True, return_tensors='pt')\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=64,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=20)\n",
    "\n",
    "    outputText = i\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        query = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "        outputText = outputText + ' ' +  query\n",
    "    outputColumn.append(outputText)\n",
    "    if cont % 100 == 0:\n",
    "        print(cont)\n",
    "        print(cont/df.size)\n",
    "    cont += 1\n",
    "df['expandedText'] = outputColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expandedText'] = outputColumn\n",
    "df = df[['id', 'expandedText', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('expanded_data.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
